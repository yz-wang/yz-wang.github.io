---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---


<html>
<head>
<style>
  /* Define a class to set line height */
  .narrow-line-height {
    line-height: 1; /* Adjust as needed for tighter line spacing */
  }
  /* Define a class to reduce margin spacing */
  .reduce-margin {
    margin-bottom: 0; /* Adjust as needed for reduced paragraph spacing */
  }
</style>
</head>
<body>


<p><font face="Arial" size="4"><b>2024</b></font></p>

<ul>
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
               MFFDNet: Single Image Deraining via Dual-Channel Mixed Feature Fusion <br> 
         <i>   Wenyin Tao, Xuefeng Yan, <b>Yongzhen Wang</b>, and Mingqiang Wei. </i><br> 
	       IEEE Transactions on Instrumentation & Measurement (<b>T-IM</b>), accepted, 2024. <br>
	  </font>
	 </p> </li>
	
</ul>

	
<p><font face="Arial" size="4"><b>2023</b></font></p>

<ul>


    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
               USCFormer: Unified Transformer with Semantically Contrastive Learning for Image Dehazing <br> 
         <i>   <b>Yongzhen Wang</b>, Jiamei Xiong, Xuefeng Yan, and Mingqiang Wei. </i><br> 
	       IEEE Transactions on Intelligent Transportation Systems, 2023. <br>
	       [<a href="https://ieeexplore.ieee.org/document/10143384">paper</a>] 
         [<a href="https://github.com/yz-wang/USCFormer">code</a>]
	  </font>
	 </p> </li>

	
     <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Cycle-SNSPGAN: Towards Real-World Image Dehazing via Cycle Spectral Normalized Soft Likelihood Estimation Patch GAN <br> 
         <i>  <b>Yongzhen Wang</b>, Xuefeng Yan, Donghai Guan. </i><br> 
	       IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>IEEE TPAMI</b>), vol. 45, no. 3, pp. 3259-3273, 2023. <br>
	       [<a href="https://ieeexplore.ieee.org/document/9804810">paper</a>]
	       [<a href="https://arxiv.org/abs/2207.04614">arXiv</a>]
	       [<a href="https://github.com/stevewongv/SSIS">code</a>] 
	       [<a href="https://drive.google.com/drive/folders/1MKxyq3R6AUeyLai9i9XWzG2C_n5f0ppP">SOBA dataset</a>]
          </font>
	 </p> </li>

     <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            IDRNet: Intervention-Driven Relation Network for Semantic Segmentation  <br> 
	 <i>   Zhenchao Jin, <b>Xiaowei Hu</b>, Lingting Zhu, Luchuan Song, Li Yuan, Lequan Yu. </i><br> 
               Neural Information Processing Systems (<b>NeurIPS</b>), to appear, 2023. <br>
	        [<a href="https://arxiv.org/abs/2310.10755">arXiv</a>] 
	        [<a href="https://github.com/SegmentationBLWX/sssegmentation">code</a>]
	 </font>
	 </p> </li>
    
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            SILT: Shadow-Aware Iterative Label Tuning for Learning to Detect Shadows from Noisy Labels <br> 
         <i>   Han Yang^, Tianyu Wang^, <b>Xiaowei Hu*</b>, and Chi-Wing Fu.  </i><br> 
	       IEEE International Conference on Computer Vision (<b>ICCV</b>), pp. 12687-12698, 2023. <br>
	       [<a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_SILT_Shadow-Aware_Iterative_Label_Tuning_for_Learning_to_Detect_Shadows_ICCV_2023_paper.pdf">paper</a>]
	       [<a href="https://arxiv.org/abs/2308.12064">arXiv</a>]
	       [<a href="https://github.com/Cralence/SILT">code</a>]
	  </font>
	 </p> </li>	
	
     <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Learning Weather-General and Weather-Specific Features for Image Restoration Under Multiple Adverse Weather Conditions <br> 
         <i>   Yurui Zhu^, Tianyu Wang^, Xueyang Fu*, Xuanyu Yang, Xin Guo, Jifeng Dai, Yu Qiao, and <b>Xiaowei Hu</b>*.  </i><br> 
	       IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), pp. 21747-21758, 2023. <br>
	       [<a href="https://openaccess.thecvf.com/content/CVPR2023/html/Zhu_Learning_Weather-General_and_Weather-Specific_Features_for_Image_Restoration_Under_Multiple_CVPR_2023_paper.html">paper</a>]
	       [<a href="https://github.com/zhuyr97/WGWS-Net">code</a>]
	     </font>
	 </p> </li>
	
     <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Video Dehazing via a Multi-Range Temporal Alignment Network with Physical Prior <br> 
         <i>   Jiaqi Xu, <b>Xiaowei Hu</b>*, Lei Zhu*, Qi Dou, Jifeng Dai, Yu Qiao, and Pheng-Ann Heng. </i><br> 
	       IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), pp. 18053-18062, 2023. <br>
	       [<a href="https://openaccess.thecvf.com/content/CVPR2023/html/Xu_Video_Dehazing_via_a_Multi-Range_Temporal_Alignment_Network_With_Physical_CVPR_2023_paper.html">paper</a>] 
	       [<a href="https://arxiv.org/abs/2303.09757">arXiv</a>] 
	       [<a href="https://github.com/jiaqixuac/MAP-Net">code</a>]
	       [<a href="https://github.com/jiaqixuac/MAP-Net/blob/main/docs/dataset_prepare.md">HazeWorld dataset</a>]
	       [<a href="https://zhuanlan.zhihu.com/p/621608857">report (zhihu)</a>]
	  </font>
	 </p> </li>
	
     <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
               Matching Is Not Enough: A Two-Stage Framework for Category-Agnostic Pose Estimation <br> 
         <i>   Min Shi, Zihao Huang, Xianzheng Ma, <b>Xiaowei Hu</b>, and Zhiguo Cao. </i><br> 
	       IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), pp. 7308-7317, 2023. (<span style="color:rgb(224, 145, 92)"><b>Highlight</b></span>)  <br>
	       [<a href="https://openaccess.thecvf.com/content/CVPR2023/html/Shi_Matching_Is_Not_Enough_A_Two-Stage_Framework_for_Category-Agnostic_Pose_CVPR_2023_paper.html">paper</a>]
	       [<a href="https://github.com/flyinglynx/CapeFormer">code</a>]
	     </font>
	 </p> </li>
	
     <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
               InternImage: Exploring Large-Scale Vision Foundation Models with Deformable Convolutions <br> 
         <i>   Wenhai Wang, Jifeng Dai, Zhe Chen, Zhenhang Huang, Zhiqi Li, Xizhou Zhu, <b>Xiaowei Hu</b>, Tong Lu, Lewei Lu, Hongsheng Li, Xiaogang Wang, and Yu Qiao. </i><br> 
	       IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), pp. 14408-14419, 2023. (<span style="color:rgb(224, 145, 92)"><b>Highlight</b></span>) <br>
	       [<a href="https://openaccess.thecvf.com/content/CVPR2023/html/Wang_InternImage_Exploring_Large-Scale_Vision_Foundation_Models_With_Deformable_Convolutions_CVPR_2023_paper.html">paper</a>] 
	       [<a href="https://arxiv.org/abs/2211.05778">arXiv</a>] 
	       [<a href="https://github.com/OpenGVLab/InternImage">code</a>]
	       [<a href="https://www.youtube.com/watch?v=_LEitBd5Tfs">video</a>]
	  </font>
	 </p> </li>

	
     <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Deep Texture-Aware Features for Camouflaged Object Detection <br> 
         <i>   Jingjing Ren^, <b>Xiaowei Hu</b>^, Lei Zhu, Xuemiao Xu, Yangyang Xu, Weiming Wang, Zijun Deng, and Pheng-Ann Heng.   </i><br> 
	        IEEE Transactions on Circuits and Systems for Video Technology (<b>IEEE TCSVT</b>), vol. 33, no. 3, pp. 1157-1167, 2023. <br>
	        [<a href="https://ieeexplore.ieee.org/document/9606888">paper</a>]
	        [<a href="https://arxiv.org/abs/2102.02996">arXiv</a>] 
	  </font>
	 </p> </li>  
	
   
      <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Representative Feature Alignment for Adaptive Object Detection <br> 
         <i>   Shan Xu, Huaidong Zhang, Xuemiao Xu*, <b>Xiaowei Hu</b>*, Yangyang Xu, Liangui Dai, Kup-Sze Choi, and Pheng-Ann Heng. </i><br> 
	        IEEE Transactions on Circuits and Systems for Video Technology (<b>IEEE TCSVT</b>), vol. 33, no. 2, pp. 689-700, 2023. <br>
	     [<a href="https://ieeexplore.ieee.org/document/9868052">paper</a>]
	  </font>
	 </p> </li>    


        
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Spectrum and Style Transformation Framework for Omni-Domain COVID-19 Diagnosis <br> 
         <i>   Zhenkun Wang, Shuangchun Gui, Xinpeng Ding, <b>Xiaowei Hu</b>*, Xiaowei Xu*, and Xiaomeng Li. </i><br> 
	       IEEE Transactions on Emerging Topics in Computational Intelligence (<b>IEEE TETCI</b>), vol. 7, no. 5, pp. 1527-1538, 2023. <br>
	       [<a href="https://ieeexplore.ieee.org/document/9954228">paper</a>]
	  </font>
	 </p> </li>   
	
	
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Dynamic Message Propagation Network for RGB-D and Video Salient Object Detection <br> 
         <i>   Baian Chen, Zhilei Chen, <b>Xiaowei Hu</b>, Jun Xu, Haoran Xie, Jing Qin, and Mingqiang Wei.  </i><br> 
	        ACM Transactions on Multimedia Computing Communications and Applications (<b>ACM TOMM</b>), accepted, 2023. <br>
	        [<a href="https://arxiv.org/abs/2206.09552">arXiv</a>]  
	  </font>
	 </p> </li>  
	
	
</ul>		
<p><font face="Arial" size="4"><b>2022</b></font></p> 
<ul>

     <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
               Video Instance Shadow Detection <br> 
         <i>   Zhenghao Xing^, Tianyu Wang^, <b>Xiaowei Hu</b>*, Haoran Wu, Chi-Wing Fu, and Pheng-Ann Heng.  </i><br> 
	       Arxiv Tech Report, 2022. <br>
	       [<a href="https://arxiv.org/abs/2211.12827">arXiv</a>] 
	  </font>
	 </p> </li>
	
     <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
               Demystify Transformers & Convolutions in Modern Image Deep Networks <br> 
         <i>   <b>Xiaowei Hu</b>^, Min Shi^, Weiyun Wang^, Sitong Wu^, Linjie Xing, Wenhai Wang, Xizhou Zhu, Lewei Lu, Jie Zhou, Xiaogang Wang, Yu Qiao, and Jifeng Dai*.  </i><br> 
	       Arxiv Tech Report, 2022. <br>
	       [<a href="https://arxiv.org/abs/2211.05781">arXiv</a>] 
	       [<a href="https://github.com/OpenGVLab/STM-Evaluation">code</a>]
	  </font>
	 </p> </li>
	
	
     <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Sparse2Dense: Learning to Densify 3D Features for 3D Object Detection  <br> 
	 <i>   Tianyu Wang, <b>Xiaowei Hu</b>*, Zhengze Liu, and Chi-Wing Fu. </i><br> 
               Neural Information Processing Systems (<b>NeurIPS</b>), 2022. <br>
	       [<a href="https://openreview.net/pdf?id=P6uZ7agiyCT">paper</a>]
	       [<a href="https://arxiv.org/pdf/2211.13067.pdf">arXiv</a>] 
	       [<a href="https://github.com/stevewongv/Sparse2Dense">code</a>]
	 </font>
	 </p> </li>
	
     <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Learning Shadow Correspondence for Video Shadow Detection  <br> 
	 <i>   Xinpeng Ding, Jingwen Yang, <b>Xiaowei Hu</b>, and Xiaomeng Li. </i><br> 
               European Conference on Computer Vision (<b>ECCV</b>), pp. 705-722, 2022. <br>
	      [<a href="https://link.springer.com/chapter/10.1007/978-3-031-19790-1_42">paper</a>]
	      [<a href="https://arxiv.org/abs/2208.00150">arXiv</a>]
	      [<a href="https://github.com/xmed-lab/SC-Cor">code</a>] 
	 </font>
	 </p> </li>
	
     <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Enhanced Coarse-to-Fine Network for Image Restoration  <br> 
	 <i>   Yurui Zhu, Xi Wang, Xueyang Fu*, and <b>Xiaowei Hu</b>*. </i><br> 
               1st Mobile Intelligent Photography & Imaging Workshop @ ECCV 2022, pp. 130-146, 2022. <br>
	       [<a href="https://link.springer.com/chapter/10.1007/978-3-031-25072-9_9">paper</a>]
	       [<a href="https://xw-hu.github.io/paper_material/ECCV22_award_certificates.pdf">certificate</a>]
	       [<a href="https://github.com/zhuyr97/ECFNet">code</a>] 
	 </font>
	 </p> </li>
	
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Enhancing Pseudo Label Quality for Semi-Supervised Domain-Generalized Medical Image Segmentation <br> 
         <i>   Huifeng Yao, <b>Xiaowei Hu</b>, and Xiaomeng Li. </i><br> 
	       AAAI Conference on Artificial Intelligence (<b>AAAI</b>), pp. 3099-3107, 2022. <br>
	    [<a href="https://ojs.aaai.org/index.php/AAAI/article/download/20217/19976">paper</a>]
	    [<a href="https://arxiv.org/abs/2201.08657">arXiv</a>]
	    [<a href="https://github.com/xmed-lab/EPL_SemiDG">code</a>] 
	  </font>
	 </p> </li>	

	
</ul>		
<p><font face="Arial" size="4"><b>2021</b></font></p> 
<ul>
   <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Revisiting Shadow Detection: A New Benchmark Dataset for Complex World <br> 
         <i>   <b>Xiaowei Hu</b>, Tianyu Wang, Chi-Wing Fu, Yitong Jiang, Qiong Wang, and Pheng-Ann Heng. </i><br> 
	       IEEE Transactions on Image Processing (<b>IEEE TIP</b>), vol. 30, pp. 1925-1934, 2021. <br>
	    [<a href="https://ieeexplore.ieee.org/document/9319520">paper</a>]
	    [<a href="https://arxiv.org/abs/1911.06998">arXiv</a>]
	    [<a href="https://github.com/xw-hu/CUHK-Shadow#cuhk-shadow-dateset">CUHK-Shadow dataset</a>]
	    [<a href="https://github.com/xw-hu/CUHK-Shadow#cuhk-shadow-evaluation">evaluation function</a>]
	    [<a href="https://github.com/xw-hu/FSDNet">code</a>] 
	  </font>
	 </p> </li>	
	
	
   <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Single-Image Real-Time Rain Removal Based on Depth-Guided Non-Local Features <br> 
         <i>   <b>Xiaowei Hu</b>, Lei Zhu, Tianyu Wang, Chi-Wing Fu, and Pheng-Ann Heng.  </i><br> 
	       IEEE Transactions on Image Processing (<b>IEEE TIP</b>), vol. 30, pp. 1759-1770, 2021. <br>
	 [<a href="https://ieeexplore.ieee.org/document/9318521">paper</a>]
	 [<a href="https://github.com/xw-hu/DGNL-Net/">code</a>] 
	 [<a href="https://www.cityscapes-dataset.com/downloads/">RainCityscapes dataset</a>]  
	 </font>
	 </p> </li>
	
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Single-Stage Instance Shadow Detection with Bidirectional Relation Learning <br> 
         <i>   Tianyu Wang^, <b>Xiaowei Hu</b>^*, Chi-Wing Fu, and Pheng-Ann Heng.  </i><br> 
	       IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), pp. 1-11, 2021. (<span style="color:rgb(224, 145, 92)"><b>Oral</b></span>) <br>
	       [<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Single-Stage_Instance_Shadow_Detection_With_Bidirectional_Relation_Learning_CVPR_2021_paper.pdf">paper</a>]
	    [<a href="https://openaccess.thecvf.com/content/CVPR2021/supplemental/Wang_Single-Stage_Instance_Shadow_CVPR_2021_supplemental.pdf">supp.</a>]
	    [<a href="https://youtu.be/p0b_2SsFypw">video</a>] 
	    [<a href="https://github.com/stevewongv/SSIS">code</a>] 
	    [<a href="https://xw-hu.github.io/paper_material/CVPR21_SSIS_poster.pdf">poster</a>] 
	  </font>
	 </p> </li>	   
	
	
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            SAC-Net: Spatial Attenuation Context for Salient Object Detection <br> 
         <i>   <b>Xiaowei Hu</b>, Chi-Wing Fu, Lei Zhu, Tianyu Wang, and Pheng-Ann Heng. </i><br> 
	        IEEE Transactions on Circuits and Systems for Video Technology (<b>IEEE TCSVT</b>), vol. 31, no. 3, pp. 1079-1090, 2021. <br>
	 [<a href="https://ieeexplore.ieee.org/document/9094635">paper</a>]
	 [<a href="https://arxiv.org/abs/1903.10152">arXiv</a>]
	 [<a href="https://ieeexplore.ieee.org/document/9094635/media#media">supp.</a>]
	 [<a href="https://github.com/xw-hu/SAC-Net">code</a>] 
	 [<a href="https://drive.google.com/open?id=1Z2WV39lxeyDBXlpNFhoxYgOmwWsoQutX">results</a>]
	  </font>
	 </p> </li>    
	
	
	
     <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Rotation-oriented Collaborative Self-supervised Learning for Retinal Disease Diagnosis  <br> 
	 <i>  Xiaomeng Li, <b>Xiaowei Hu</b>, Xiaojuan Qi, Lequan Yu, Wei Zhao, Pheng-Ann Heng, and Lei Xing. </i><br> 
              IEEE Transactions on Medical Imaging (<b>IEEE TMI</b>), vol. 40, no. 9, pp. 2284-2294, 2021. (<span style="color:rgb(224, 145, 92)"><b>TMI Popular Paper</b></span>) <br>  
	      [<a href="https://ieeexplore.ieee.org/document/9411868">paper</a>]
	      [<a href="https://github.com/xmengli/Rotation-oriented-self-supervised">code</a>] 
	 </font>
	 </p> </li>

    
     <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            SALMNet: A Structure-Aware Lane Marking Detection Network <br> 
         <i>  Xuemiao Xu, Tianfei Yu, <b>Xiaowei Hu</b>*, Wing W. Y. Ng*, and Pheng-Ann Heng. </i><br> 
              IEEE Transactions on Intelligent Transportation Systems (<b>IEEE TITS</b>), vol. 22, no. 8, pp. 4986-4997, 2021. <br>
	        [<a href="https://ieeexplore.ieee.org/document/9061152">paper</a>]
	 </font>
	 </p> </li>
	
	
   
     <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Learning Gated Non-Local Residual for Single-Image Rain Streak Removal <br> 
         <i>  Lei Zhu, Zijun Deng, <b>Xiaowei Hu</b>*, Haoran Xie, Xuemiao Xu*, Jing Qin, and Pheng-Ann Heng. </i><br> 
              IEEE Transactions on Circuits and Systems for Video Technology  (<b>IEEE TCSVT</b>), vol. 31, no. 6, pp. 2147-2159, 2021. <br> 
	        [<a href="https://ieeexplore.ieee.org/document/9187841">paper</a>]
	 </font>
	 </p> </li>
    
	
	
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Learning Semantic Context from Normal Samples for Unsupervised Anomaly Detection  <br> 
	 <i>   Xudong Yan, Huaidong Zhang, Xuemiao Xu, <b>Xiaowei Hu</b>, and Pheng-Ann Heng. </i><br> 
               AAAI Conference on Artificial Intelligence (<b>AAAI</b>), vol. 35, no. 4, pp. 3110-3118, 2021. <br>
	      [<a href="https://www.aaai.org/AAAI21Papers/AAAI-4221.YanX.pdf">paper</a>]
	      [<a href="https://github.com/Xudong-Yan/SCADN">code</a>] 
	 </font>
	 </p> </li> 

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Global Guidance Network for Breast Lesion Segmentation in Ultrasound Images  <br> 
	 <i>  Cheng Xue, Lei Zhu, Huazhu Fu, <b>Xiaowei Hu</b>, Xiaomeng Li, Hai Zhang, and Pheng-Ann Heng. </i><br> 
              Medical Image Analysis (<b>MedIA</b>), vol. 70, article no. 101989, 2021. <br> 
	      [<a href="https://www.sciencedirect.com/science/article/pii/S1361841521000359">paper</a>]
	      [<a href="https://arxiv.org/abs/2104.01896">arXiv</a>]
	 </font>
	 </p> </li>
	
	
</ul>	
<p><font face="Arial" size="4"><b>2020</b></font></p> 
<ul>
   <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Direction-Aware Spatial Context Features for Shadow Detection and Removal <br> 
         <i>   <b>Xiaowei Hu</b>, Chi-Wing Fu, Lei Zhu, Jing Qin, and Pheng-Ann Heng. </i><br> 
	       IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>IEEE TPAMI</b>), vol. 42, no. 11, pp. 2795-2808, 2020. <br>
	 [<a href="https://ieeexplore.ieee.org/document/8723605">paper</a>]
	 [<a href="https://arxiv.org/abs/1805.04635">arXiv</a>]
	 [<a href="https://ieeexplore.ieee.org/document/8723605/media#media">supp.</a>]
	 [<a href="https://github.com/xw-hu/DSC">code</a>] </font>
	 </p> </li>	
	
	
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Instance Shadow Detection <br> 
         <i>   Tianyu Wang^, <b>Xiaowei Hu</b>^, Qiong Wang, Pheng-Ann Heng, and Chi-Wing Fu.  </i><br> 
	       IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), pp. 1880-1889, 2020. <br>
	    [<a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Instance_Shadow_Detection_CVPR_2020_paper.pdf">paper</a>]
	    [<a href="https://arxiv.org/abs/1911.07034">arXiv</a>]
	    [<a href="https://github.com/stevewongv/InstanceShadowDetection">code</a>]
	    [<a href="https://drive.google.com/drive/folders/1MKxyq3R6AUeyLai9i9XWzG2C_n5f0ppP">SOBA dataset</a>]
	    [<a href="https://drive.google.com/file/d/1VHP8qm_FZeKR6_zMtNt3SxvBTvfEK7I8/view">results</a>]
	    [<a href="https://crossminds.ai/video/instance-shadow-detection-5f6e7779d81cf36f1a8e32a8/">video</a>] 
	  </font>
	 </p> </li>	
	
	
     <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Saliency-Aware Texture Smoothing <br> 
         <i>   Lei Zhu^, <b>Xiaowei Hu</b>^, Chi-Wing Fu, Jing Qin, and Pheng-Ann Heng.  </i><br> 
	       IEEE Transactions on Visualization and Computer Graphics (<b>IEEE TVCG</b>), vol. 26, no. 7, pp. 2471-2484, 2020. <br>
	 [<a href="https://ieeexplore.ieee.org/document/8585158">paper</a>]
	 [<a href="https://github.com/xw-hu/GNLB">code</a>] 
	 [<a href="https://drive.google.com/file/d/1vo7kYFyaPRYQtj8b196sXy2FoN8oPnNZ">SDTS dataset</a>] </font>
	 </p> </li>	

	
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Ψ-Net: Stacking Densely Convolutional LSTMs for Sub-cortical Brain Structure Segmentation  <br> 
	 <i>  Lihao Liu^, <b>Xiaowei Hu</b>^, Lei Zhu, Chi-Wing Fu, Jing Qin, and Pheng-Ann Heng.  </i><br>
              IEEE Transactions on Medical Imaging (<b>IEEE TMI</b>), vol. 39, no. 9, pp. 2806-2817, 2020. <br>
	      [<a href="https://ieeexplore.ieee.org/document/9007625">paper</a>]
	      [<a href="https://github.com/lihaoliu-cambridge/psi-net">code</a>] 
	 </font>
	 </p> </li>
	
	
     <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            CANet: Cross-disease Attention Network for Joint Diabetic Retinopathy and Diabetic Macular Edema Grading  <br> 
	 <i>   Xiaomeng Li*, <b>Xiaowei Hu</b>*, Lequan Yu, Lei Zhu, Chi-Wing Fu, and Pheng-Ann Heng.</i><br> 
              IEEE Transactions on Medical Imaging (<b>IEEE TMI</b>), vol. 39, no. 5, pp. 1483-1493, 2020. 
	     (<span style="color:rgb(224, 145, 92)"><b>ESI Highly Cited Paper</b></span>) <br>
	 [<a href="https://ieeexplore.ieee.org/document/8892667">paper</a>]
         [<a href="https://github.com/xmengli999/CANet">code</a>] 
	 </font>
	 </p> </li>
	
      
     <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            GrabAR: Occlusion-aware Grabbing Virtual Objects in AR <br> 
         <i>   Xiao Tang, <b>Xiaowei Hu</b>, Chi-Wing Fu, and Daniel Cohen-Or. </i><br> 
	       ACM Symposium on User Interface Software and Technology (<b>UIST</b>), pp. 697-708, 2020. <br>
	    [<a href="https://dl.acm.org/doi/abs/10.1145/3379337.3415835">paper</a>]
	    [<a href="https://arxiv.org/abs/1912.10637">arXiv</a>]
	    [<a href="https://wbstx.github.io/grabar/">project</a>] 
	  </font>
	  </p> </li>
	
   
     <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Aggregating Attentional Dilated Features for Salient Object Detection  <br> 
	 <i>   Lei Zhu, Jiaxing Chen, <b>Xiaowei Hu</b>, Chi-Wing Fu, Xuemiao Xu, Jing Qin, and Pheng-Ann Heng.</i><br> 
              IEEE Transactions on Circuits and Systems for Video Technology (<b>IEEE TCSVT</b>), vol. 30, no. 10, pp. 3358-3371, 2020. <br> 
	 [<a href="https://ieeexplore.ieee.org/document/8836095">paper</a>]
	 [<a href="https://github.com/githubBingoChen/AADF-Net">code</a>]
	 [<a href="https://drive.google.com/file/d/1tv72yWNH0ANHoSU4qMOwD7g5r53wSZEe/view">results</a>]
	 </font>
	 </p> </li>

	
</ul>	
<p><font face="Arial" size="4"><b>2019</b></font></p> 
<ul>
	
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Mask-ShadowGAN: Learning to Remove Shadows from Unpaired Data <br> 
         <i>   <b>Xiaowei Hu</b>, Yitong Jiang, Chi-Wing Fu, and Pheng-Ann Heng. </i><br> 
	       IEEE International Conference on Computer Vision (<b>ICCV</b>), pp. 2472-2481, 2019. <br>
	 [<a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Hu_Mask-ShadowGAN_Learning_to_Remove_Shadows_From_Unpaired_Data_ICCV_2019_paper.pdf">paper</a>]
	 [<a href="https://arxiv.org/abs/1903.10683">arXiv</a>]
	 [<a href="https://github.com/xw-hu/Mask-ShadowGAN">code</a>] 
	 [<a href="https://drive.google.com/open?id=1PPAX0W4eyfn1cUrb2aBefnbrmhB1htoJ">USR dataset</a>]  
	 [<a href="https://xw-hu.github.io/paper_material/ICCV19_MaskShadowGAN_poster.pdf">poster</a>]  
	  </font>
	 </p> </li>	
	
	
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Deep Multi-Model Fusion for Single-Image Dehazing <br> 
         <i>   Zijun Deng, Lei Zhu, <b>Xiaowei Hu</b>, Chi-Wing Fu, Xuemiao Xu, Qing Zhang, Jing Qin, and Pheng-Ann Heng. </i><br> 
	       IEEE International Conference on Computer Vision (<b>ICCV</b>), pp. 2453-2462, 2019. <br> 
	    [<a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Deng_Deep_Multi-Model_Fusion_for_Single-Image_Dehazing_ICCV_2019_paper.pdf">paper</a>]
	    [<a href="https://github.com/zijundeng/DM2F-Net">code</a>] 
	    [<a href="https://drive.google.com/drive/folders/1ZVBI_3Y2NthVLeK7ODMIB5vRjmN9payF">results</a>]
	  </font>
	 </p> </li>	
	


    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Depth-Attentional Features for Single-Image Rain Removal <br> 
         <i>   <b>Xiaowei Hu</b>, Chi-Wing Fu, Lei Zhu, and Pheng-Ann Heng.  </i><br> 
	       IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), pp. 8022-8031, 2019. <br>
	 [<a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Hu_Depth-Attentional_Features_for_Single-Image_Rain_Removal_CVPR_2019_paper.pdf">paper</a>]
	 [<a href="http://openaccess.thecvf.com/content_CVPR_2019/supplemental/Hu_Depth-Attentional_Features_for_CVPR_2019_supplemental.pdf">supp.</a>]
	 [<a href="https://github.com/xw-hu/DAF-Net">code</a>] 
	 [<a href="https://www.cityscapes-dataset.com/downloads/">RainCityscapes dataset</a>]  
	 [<a href="https://xw-hu.github.io/paper_material/CVPR19_derain_poster.pdf">poster</a>]  
	 </font>
	 </p> </li>	

	
	
     <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            SINet: A Scale-Insensitive Convolutional Neural Network for Fast Vehicle Detection  <br> 
         <i>  <b>Xiaowei Hu</b>, Xuemiao Xu, Yongjie Xiao, Hao Chen, Shengfeng He, Jing Qin, and Pheng-Ann Heng. </i> <br> 
              IEEE Transactions on Intelligent Transportation Systems (<b>IEEE TITS</b>), vol. 20, no. 3, pp. 1010-1019, 2019. 
	      (<span style="color:rgb(224, 145, 92)"><b>ESI Highly Cited Paper</b></span>) <br>
	 [<a href="https://ieeexplore.ieee.org/document/8478157">paper</a>]
	 [<a href="https://arxiv.org/abs/1804.00433">arXiv</a>]
	 [<a href="https://github.com/xw-hu/SINet">code</a>] 
	 [<a href="https://drive.google.com/file/d/1raH0LF-hADB4BZmU9SAv19EWV6dxyQAw/view">LSVH dataset (Google)</a>]
	 [<a href="https://pan.baidu.com/s/1lrasgXOUVC-qX_yb6t1fKA">LSVH dataset (Baidu)</a>] </font>
	 </p> </li>
	

     <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Probabilistic Multilayer Regularization Network for Unsupervised 3D Brain Image Registration  <br> 
	 <i>   Lihao Liu, <b>Xiaowei Hu</b>, Lei Zhu, and Pheng-Ann Heng. </i><br> 
               International Conference on Medical Image Computing and Computer Assisted Intervention (<b>MICCAI</b>), pp. 346-354, 2019. <br>
	     [<a href="https://link.springer.com/chapter/10.1007/978-3-030-32245-8_39">paper</a>]
	     [<a href="https://arxiv.org/abs/1907.01922">arXiv</a>]
	     [<a href="https://github.com/liulihao-cuhk/Probabilistic-Multilayer-Regularization-Network">code</a>] 
	 </font>
	 </p> </li>
	
 
     <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Deep Attentive Features for Prostate Segmentation in 3D Transrectal Ultrasound  <br> 
	 <i>   Yi Wang, Haoran Dou, <b>Xiaowei Hu</b>, Lei Zhu, Xin Yang, Ming Xu, Jing Qin, Pheng-Ann Heng, Tianfu Wang, and Dong Ni.</i><br> 
              IEEE Transactions on Medical Imaging (<b>IEEE TMI</b>), vol. 38, no. 12, pp. 2768-2778, 2019. <br> 
	 [<a href="https://ieeexplore.ieee.org/document/8698868">paper</a>]
	 [<a href="https://arxiv.org/abs/1907.01743">arXiv</a>]
	 [<a href="https://github.com/wulalago/DAF3D">code</a>] 
	 </font>
	 </p> </li>
	
	
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Enhancing Augmented VR Interaction via Egocentric Scene Analysis  <br> 
	 <i>   Yang Tian, Chi-Wing Fu, Shengdong Zhao, Ruihui Li, Xiao Tang, <b>Xiaowei Hu</b>, and Pheng-Ann Heng.</i><br> 
              Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (<b>Ubicomp</b>), <br> 
	      vol. 3, no. 3, article no. 105, 2019. <br> 
	 [<a href="https://dl.acm.org/citation.cfm?doid=3361560.3351263">paper</a>]
	 </font>
	 </p> </li>
	
	
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            CATARACTS: Challenge on Automatic Tool Annotation for cataRACT Surgery  <br> 
	 <i>  Hassan Al Hajj, Mathieu Lamard, Pierre-Henri Conze, Soumali Roychowdhury, <b>Xiaowei Hu</b>, et al.</i><br> 
              Medical Image Analysis (<b>MedIA</b>), vol. 52, pp. 24-41, 2019. <br> 
	 [<a href="https://www.sciencedirect.com/science/article/abs/pii/S136184151830865X">paper</a>]
	 </font>
	 </p> </li>
	

	
</ul>	
<p><font face="Arial" size="4"><b>2018 & before</b></font></p> 
<ul> 
	
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Direction-Aware Spatial Context Features for Shadow Detection  <br> 
	 <i>   <b>Xiaowei Hu</b>, Lei Zhu, Chi-Wing Fu, Jing Qin, and Pheng-Ann Heng. </i><br> 
	       IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), pp. 7454-7462, 2018. (<span style="color:rgb(224, 145, 92)"><b>Oral</b></span>) <br> 
	 [<a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Hu_Direction-Aware_Spatial_Context_CVPR_2018_paper.pdf">paper</a>]
	 [<a href="https://arxiv.org/abs/1712.04142">arXiv</a>]
	 [<a href="https://xw-hu.github.io/paper_material/CVPR18_DSC_supp.pdf">supp.</a>]
	 [<a href="https://github.com/xw-hu/DSC">code</a>]
	 [<a href="https://drive.google.com/open?id=1DCTqEnYJ8ADBqShBzXFYKa_yD-YZKEo7">results</a>] 
	 [<a href="https://xw-hu.github.io/paper_material/CVPR18_DSC_poster.pdf">poster</a>]   
	 [<a href="https://xw-hu.github.io/paper_material/CVPR18_DSC_slides.pdf">slides</a>]  
	 [<a href="https://www.youtube.com/watch?v=zVYY9HaEJnc&t=1195s">video</a>] </font>
	 </p> </li>
	 <!-- Tech report, arXiv, Dec. 2017  </font><br> -->
	
   
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Recurrently Aggregating Deep Features for Salient Object Detection  <br> 
	 <i>   <b>Xiaowei Hu</b>, Lei Zhu, Jing Qin, Chi-Wing Fu, and Pheng-Ann Heng. </i><br> 
               AAAI Conference on Artificial Intelligence (<b>AAAI</b>), pp. 6943-6950, 2018. (<span style="color:rgb(224, 145, 92)"><b>Spotlight</b></span>)<br>
	 [<a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16775/16281">paper</a>]
	 [<a href="https://xw-hu.github.io/paper_material/AAAI18_RADF_supp.pdf">supp.</a>]
	 [<a href="https://github.com/xw-hu/RADF">code</a>] 
	 [<a href="https://drive.google.com/drive/folders/0B8VpfLBo2BeyNWxnMURWNlU0YVE">results</a>] 
	 [<a href="https://xw-hu.github.io/paper_material/AAAI18_RADF_poster.pdf">poster</a>]  </font>
	 </p> </li> 
	
	
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            R<sup>3</sup>Net: Recurrent Residual Refinement Network for Saliency Detection  <br> 
	 <i>   Zijun Deng^, <b>Xiaowei Hu</b>^, Lei Zhu, Xuemiao Xu, Jing Qin, Guoqiang Han, and Pheng-Ann Heng.  </i><br> 
               International Joint Conference on Artificial Intelligence (<b>IJCAI</b>), pp. 684-690, 2018. (<span style="color:rgb(224, 145, 92)"><b>Oral</b></span>) <br>
	 [<a href="https://www.ijcai.org/proceedings/2018/0095.pdf">paper</a>]
	 [<a href="https://github.com/zijundeng/R3Net">code</a>]
	 [<a href="https://drive.google.com/open?id=1PloaTokZEfWPy8voDm7mp3yvHnXCtn2c">results</a>] 
	 [<a href="https://xw-hu.github.io/paper_material/IJCAI18_R3Net_poster.pdf">poster</a>]
	 [<a href="https://xw-hu.github.io/paper_material/IJCAI18_R3Net_slides.pdf">slides</a>]
	    </font>
	 </p> </li>
	
    	
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Bidirectional Feature Pyramid Network with Recurrent Attention Residual Modules for Shadow Detection  <br> 
	 <i>   Lei Zhu, Zijun Deng, <b>Xiaowei Hu</b>, Chi-Wing Fu, Xuemiao Xu, Jing Qin, and Pheng-Ann Heng. </i><br> 
               European Conference on Computer Vision (<b>ECCV</b>), pp. 122-137, 2018. <br>
	 [<a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Lei_Zhu_Bi-directional_Feature_Pyramid_ECCV_2018_paper.pdf">paper</a>]
	 [<a href="https://github.com/zijundeng/BDRAR">code</a>]
	 [<a href="https://xw-hu.github.io/paper_material/ECCV18_BDRAR_poster.pdf">poster</a>]  
	 </font>
	 </p> </li>	
	
   
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Deep Attentional Features for Prostate Segmentation in Ultrasound  <br> 
	 <i>   Yi Wang, Zijun Deng, <b>Xiaowei Hu</b>, Lei Zhu, Xin Yang, Xuemiao Xu, Pheng-Ann Heng, and Dong Ni. </i><br> 
               International Conference on Medical Image Computing and Computer Assisted Intervention (<b>MICCAI</b>), pp. 523-530, 2018. <br>
	 [<a href="https://link.springer.com/chapter/10.1007/978-3-030-00937-3_60">paper</a>]
	 [<a href="https://github.com/zijundeng/DAF">code</a>] </font>
	 </p> </li>
	
	
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            AGNet: Attention-Guided Network for Surgical Tool Presence Detection  <br> 
	 <i>   <b>Xiaowei Hu</b>, Lequan Yu, Hao Chen, Jing Qin, and Pheng-Ann Heng. </i><br> 
		Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support, pp. 186-194, 2017. <br>
	 [<a href="https://link.springer.com/chapter/10.1007/978-3-319-67558-9_22">paper</a>] 
	 [<a href="https://github.com/xw-hu/AGNet">code</a>] </font>
	 </p> </li>
	
</ul>

<p><font face="Arial" size="4"><b>PhD Thesis</b></font></p> 
<ul>
     <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Shadow Detection and Removal with Deep Learning <br> 
	       The Chinese University of Hong Kong, June, 2020.
          </font>
	 </p> </li>
</ul>
</body>
</html>
